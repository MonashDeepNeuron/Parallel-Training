{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import ta\n",
    "import requests\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import RadioButtons\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.dates import DateFormatter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'AVGO', 'ADBE', 'CRM',\n",
    "    'CSCO', 'INTC', 'AMD', 'QCOM', 'ORCL', 'TXN', 'INTU', 'AMAT', 'MU', 'NOW',\n",
    "    'SHOP', 'PANW', 'SNOW', 'ZM', 'PLTR', 'UBER', 'LYFT', 'DOCU', 'FSLY', 'TWLO'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"B6WMMM9S4ZYE4KRT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for AAPL\n",
      "Full response: {'Information': 'We have detected your API key as your_api_key and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:12<00:12, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for MSFT\n",
      "Full response: {'Information': 'We have detected your API key as your_api_key and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:25<00:00, 12.75s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m     90\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_all_alpha_stocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstock_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# This will save the combined dataframe to 'stock_data.csv' locally in the working directory\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 77\u001b[0m, in \u001b[0;36mfetch_all_alpha_stocks\u001b[0;34m(tickers, output_csv)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Avoid hitting the API rate limit\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m12\u001b[39m)  \u001b[38;5;66;03m# Sleep for 12 seconds between requests to avoid rate limits\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     79\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import ta\n",
    "\n",
    "# Assuming API_KEY is defined\n",
    "API_KEY = 'your_api_key'\n",
    "\n",
    "def fetch_alpha_vantage_stock(ticker, interval='1min', outputsize='full'):\n",
    "    url = f'https://www.alphavantage.co/query'\n",
    "    params = {\n",
    "        'function': 'TIME_SERIES_INTRADAY',\n",
    "        'symbol': ticker,\n",
    "        'interval': interval,\n",
    "        'outputsize': outputsize,\n",
    "        'apikey': API_KEY\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, params=params)\n",
    "    data = r.json()\n",
    "\n",
    "    # Check for error messages or empty data\n",
    "    if \"Error Message\" in data or \"Note\" in data:\n",
    "        print(f\"Error for {ticker}: {data.get('Error Message', data.get('Note'))}\")\n",
    "        return None\n",
    "    \n",
    "    key = f'Time Series ({interval})'\n",
    "    if key not in data:\n",
    "        print(f\"No data for {ticker}\")\n",
    "        print(f\"Full response: {data}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data[key]).T\n",
    "    df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    df = df.astype(float)\n",
    "    df['Ticker'] = ticker\n",
    "\n",
    "    # Compute additional columns\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['EMA_2'] = df['Close'].ewm(span=2, adjust=False).mean()\n",
    "\n",
    "    rsi = ta.momentum.RSIIndicator(close=df['Close'])\n",
    "    df['RSI'] = rsi.rsi()\n",
    "\n",
    "    macd = ta.trend.MACD(close=df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_Signal'] = macd.macd_signal()\n",
    "    df['MACD_Diff'] = macd.macd_diff()\n",
    "\n",
    "    bb = ta.volatility.BollingerBands(close=df['Close'])\n",
    "    df['BB_High'] = bb.bollinger_hband()\n",
    "    df['BB_Low'] = bb.bollinger_lband()\n",
    "\n",
    "    df['Volume_EMA'] = df['Volume'].ewm(span=20).mean()\n",
    "    df['Volatility'] = df['Log_Returns'].rolling(window=60).std()\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_all_alpha_stocks(tickers, output_csv=None):\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in tqdm(tickers):\n",
    "        df = fetch_alpha_vantage_stock(ticker)\n",
    "        if df is not None:\n",
    "            all_data.append(df)\n",
    "        \n",
    "        # Avoid hitting the API rate limit\n",
    "        time.sleep(12)  # Sleep for 12 seconds between requests to avoid rate limits\n",
    "\n",
    "    combined_df = pd.concat(all_data)\n",
    "    combined_df.index.names = ['Datetime']\n",
    "    combined_df = combined_df.sort_index()\n",
    "    \n",
    "    # If an output CSV file name is provided, save the data to a CSV\n",
    "    if output_csv:\n",
    "        combined_df.to_csv(output_csv)\n",
    "        print(f\"Data saved to {output_csv}\")\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "tickers = ['AAPL', 'MSFT']\n",
    "df = fetch_all_alpha_stocks(tickers, output_csv='stock_data.csv')\n",
    "\n",
    "# This will save the combined dataframe to 'stock_data.csv' locally in the working directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data to aurafarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark Mode Setup\n",
    "rcParams['figure.facecolor'] = '#1a1a1a'\n",
    "rcParams['axes.facecolor'] = '#2a2a2a'\n",
    "rcParams['axes.edgecolor'] = 'white'\n",
    "rcParams['text.color'] = 'white'\n",
    "rcParams['xtick.color'] = 'white'\n",
    "rcParams['ytick.color'] = 'white'\n",
    "\n",
    "# -- CORRELATION HEATMAP --\n",
    "def plot_correlation_heatmap(df):\n",
    "    pivot = df.pivot_table(index='Datetime', columns='Ticker', values='Close')\n",
    "    corr = pivot.corr()\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(corr, annot=True, cmap='GnBu', vmin=-1, vmax=1, center=0)\n",
    "    # ax.set_title('Ticker Correlation Heatmap', fontsize=16, pad=20)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    return corr\n",
    "\n",
    "# -- ANIMATED BOLLINGER BANDS --\n",
    "def animate_bollinger(ticker, df):\n",
    "    ticker_df = df[df['Ticker'] == ticker].copy()\n",
    "    ticker_df = ticker_df.sort_index()\n",
    "    ticker_df = ticker_df.last('30D')  # Requires datetime index\n",
    "\n",
    "    if ticker_df.empty:\n",
    "        print(f\"No data for {ticker} in the last 30 days.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%m-%d %H:%M'))\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        current_data = ticker_df.iloc[:frame]\n",
    "\n",
    "        ax.plot(current_data.index, current_data['Close'], label='Price', color='royalblue')\n",
    "        ax.plot(current_data.index, current_data['SMA_5'], label='SMA(5)', color='orange')\n",
    "        ax.plot(current_data.index, current_data['BB_High'], label='Upper Band', linestyle='--', color='red')\n",
    "        ax.plot(current_data.index, current_data['BB_Low'], label='Lower Band', linestyle='--', color='green')\n",
    "\n",
    "        ax.fill_between(current_data.index,\n",
    "                        current_data['BB_Low'],\n",
    "                        current_data['BB_High'],\n",
    "                        color='gray', alpha=0.2)\n",
    "\n",
    "        ax.set_title(f'{ticker} Bollinger Bands Evolution', fontsize=16)\n",
    "        ax.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=len(ticker_df), interval=100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -- 3D VOLATILITY PLOT --\n",
    "def plot_3d_volatility(df):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for ticker in df['Ticker'].unique():\n",
    "        ticker_df = df[df['Ticker'] == ticker].copy()\n",
    "        ticker_df = ticker_df.sort_index()\n",
    "        if len(ticker_df) < 2:\n",
    "            continue  # skip if not enough data\n",
    "\n",
    "        dates = pd.to_datetime(ticker_df.index).astype(np.int64) // 10**9  # numeric for 3D plot\n",
    "        ax.plot(dates,\n",
    "                ticker_df['Volatility'],\n",
    "                ticker_df['RSI'],\n",
    "                label=ticker,\n",
    "                linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('DateTime (numeric)', fontsize=12)\n",
    "    ax.set_ylabel('Volatility', fontsize=12)\n",
    "    ax.set_zlabel('RSI', fontsize=12)\n",
    "    ax.set_title('3D Volatility-RSI Timeline', fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=25, azim=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:01<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_all_alpha_stocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plot_correlation_heatmap(df)\n",
      "Cell \u001b[0;32mIn[109], line 58\u001b[0m, in \u001b[0;36mfetch_all_alpha_stocks\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m---> 58\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m combined_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     60\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnn_development/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df = fetch_all_alpha_stocks(tickers)\n",
    "\n",
    "plot_correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_all_alpha_stocks(tickers)\n",
    "\n",
    "for ticker in df:\n",
    "    animate_bollinger(ticker, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_volatility(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Close', 'Returns', 'Log_Returns', 'SMA_5', 'EMA_2', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Diff', 'BB_High', 'BB_Low', 'Volume_EMA', 'Volatility']\n",
    "df = fetch_all_alpha_stocks(tickers)\n",
    "\n",
    "def scale_features(df, feature_cols):\n",
    "    scalers = {}\n",
    "    \n",
    "    for ticker in df['Ticker'].unique():\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        idx = df['Ticker'] == ticker\n",
    "        \n",
    "        df.loc[idx, feature_cols] = scaler.fit_transform(df.loc[idx, feature_cols])\n",
    "        \n",
    "        scalers[ticker] = scaler\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\n",
    "def create_sequences(df, feature_cols, sequence_length=60):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "\n",
    "    for ticker in df['Ticker'].unique():\n",
    "        \n",
    "        df_ticker = df[df['Ticker'] == ticker]\n",
    "        \n",
    "        data = df_ticker[feature_cols].values\n",
    "        target = df_ticker['Close'].values  # or next-day close/return etc.\n",
    "        \n",
    "        \n",
    "        for i in range(sequence_length, len(df_ticker)):\n",
    "            X.append(data[i-sequence_length:i])  # past 60 days\n",
    "            y.append(target[i])  # predict next close price\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Normalising the data\n",
    "combined_df, scalers = scale_features(df, features)\n",
    "\n",
    "# Creating sequences for the LSTM and such\n",
    "X, y = create_sequences(combined_df, features, sequence_length=60) # 60 candlesticks = 1 Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
